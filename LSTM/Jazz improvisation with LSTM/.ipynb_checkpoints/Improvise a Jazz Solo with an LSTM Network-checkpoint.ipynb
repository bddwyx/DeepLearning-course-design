{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvise a Jazz Solo with an LSTM Network\n",
    "\n",
    "**You will learn to:**\n",
    "- Apply an LSTM to music generation.\n",
    "- Generate your own jazz music with deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import IPython\n",
    "import sys\n",
    "from music21 import *  # éœ€è¦pip install msgpack, music21\n",
    "import numpy as np\n",
    "from grammar import *\n",
    "from qa import *\n",
    "from preprocess import * \n",
    "from music_utils import *\n",
    "from data_utils import *\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Problem statement\n",
    "\n",
    "You would like to create a jazz music piece specially for a friend's birthday. However, you don't know any instruments or music composition. Fortunately, you know deep learning and will solve this problem using an LSTM netwok.  \n",
    "\n",
    "<img src=\"images/jazz.jpg\" style=\"width:450;height:300px;\">\n",
    "\n",
    "\n",
    "### 1.1 - Dataset\n",
    "\n",
    "ä½ å°†åœ¨çˆµå£«éŸ³ä¹çš„è¯­æ–™åº“ä¸Šè®­ç»ƒä½ çš„ç®—æ³•ã€‚è¿è¡Œä¸‹é¢çš„cellæ”¶å¬è®­ç»ƒé›†ä¸­çš„éŸ³é¢‘ç‰‡æ®µï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio('./data/30s_seq.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å·²ç»å¯¹éŸ³ä¹æ•°æ®è¿›è¡Œäº†é¢„å¤„ç†ï¼Œå‘ˆç°å‡ºçš„æ˜¯â€™value'ï¼Œä½ å¯ä»¥å°†æ¯ä¸ª'value'çœ‹ä½œä¸€ä¸ªéŸ³ç¬¦ï¼ŒåŒ…æ‹¬éŸ³è°ƒå’ŒæŒç»­æ—¶é—´ã€‚\n",
    "\n",
    "For example, if you press down a specific piano key for 0.5 seconds, then you have just played a note. In music theory, a \"value\" is actually more complicated than this--specifically, it also captures the information needed to play multiple notes at the same time.  (playng multiple notes at the same time generates what's called a \"chord\"). \n",
    "\n",
    "æˆ‘ä»¬ä¸å¿…æ‹…å¿ƒéŸ³ä¹ç†è®ºçš„ç»†èŠ‚ã€‚å¯¹äºvalueï¼Œåªéœ€è¦çŸ¥é“æˆ‘ä»¬å°†è·å¾—ä¸€ä¸ªå€¼çš„æ•°æ®é›†ï¼Œå¹¶å­¦ä¹ ä¸€ä¸ªRNNæ¨¡å‹æ¥ç”Ÿæˆå€¼çš„åºåˆ—ã€‚\n",
    "\n",
    "éŸ³ä¹ç”Ÿæˆç³»ç»Ÿå°†ä½¿ç”¨78ç§valueã€‚è¿è¡Œä»¥ä¸‹ä»£ç åŠ è½½åŸå§‹éŸ³ä¹æ•°æ®å¹¶å°†å…¶é¢„å¤„ç†ä¸ºvalueã€‚(å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, n_values, indices_values = load_music_utils()\n",
    "print('shape of X:', X.shape)\n",
    "print('number of training examples:', X.shape[0])\n",
    "print('Tx (length of sequence):', X.shape[1])\n",
    "print('total # of unique values:', n_values)\n",
    "print('Shape of Y:', Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have just loaded the following:\n",
    "\n",
    "- `X`: This is an (m, $T_x$, 78) dimensional array. We have m training examples, each of which is a snippet of $T_x =30$ musical values. At each time step, the input is one of 78 different possible values, represented as a one-hot vector. Thus for example, X[i,t,:] is a one-hot vector representating the value of the i-th example at time t. \n",
    "\n",
    "- `Y`: This is essentially the same as `X`, but shifted one step to the left. We're interested in the network using the previous values to predict the next value, so our sequence model will try to predict $y^{\\langle t \\rangle}$ given $x^{\\langle 1\\rangle}, \\ldots, x^{\\langle t \\rangle}$.\n",
    "Yä¸­çš„æ•°æ®è¢«é‡æ–°æ’åºä¸ºç»´åº¦ï¼ˆğ‘‡ğ‘¦ï¼Œğ‘šï¼Œ78ï¼‰ï¼Œå…¶ä¸­ğ‘‡ğ‘¦=ğ‘‡ğ‘¥ã€‚è¿™ç§æ ¼å¼ä½¿ä»¥åé¦ˆé€åˆ°LSTMæ›´åŠ æ–¹ä¾¿ã€‚\n",
    "\n",
    "- `n_values`: The number of unique values in this dataset. This should be 78. \n",
    "\n",
    "- `indices_values`: python dictionary mapping from 0-77 to musical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Overview of our model\n",
    "\n",
    "Here is the architecture of the model we will use. You will be implementing it in Keras. The architecture is as follows: \n",
    "\n",
    "<img src=\"images/music_generation.png\" style=\"width:600;height:400px;\">\n",
    "\n",
    "<!--\n",
    "<img src=\"images/djmodel.png\" style=\"width:600;height:400px;\">\n",
    "<br>\n",
    "<caption><center> **Figure 1**: LSTM model. $X = (x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, ..., x^{\\langle T_x \\rangle})$ is a window of size $T_x$ scanned over the musical corpus. Each $x^{\\langle t \\rangle}$ is an index corresponding to a value (ex: \"A,0.250,< m2,P-4 >\") while $\\hat{y}$ is the prediction for the next value  </center></caption>\n",
    "!--> \n",
    "\n",
    "æˆ‘ä»¬å¯¹æ¨¡å‹è®­ç»ƒæ—¶ï¼Œä»ä¸€æ®µæ›´é•¿çš„éŸ³ä¹ä¸­éšæœºæŠ½å–30ä¸ªvalueçš„ç‰‡æ®µã€‚å› æ­¤å°±ä¸ç”¨è®¾ç½®ç¬¬ä¸€ä¸ªè¾“å…¥ğ‘¥âŸ¨1âŸ©=0âƒ—ï¼Œå› ä¸ºå¤§å¤šæ•°éŸ³é¢‘ç‰‡æ®µéƒ½æ˜¯ä»éŸ³ä¹ä¸­é—´çš„æŸä¸ªä½ç½®å¼€å§‹çš„ã€‚æˆ‘ä»¬å°†æ¯ä¸ªç‰‡æ®µéƒ½è®¾ç½®ä¸ºå…·æœ‰ç›¸åŒçš„é•¿åº¦ğ‘‡ğ‘¥=30ï¼Œè¿™æ ·åšçŸ¢é‡åŒ–æ›´å®¹æ˜“ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Building the model\n",
    "\n",
    "In this part you will build and train a model. \n",
    "\n",
    "To do so, you will need to build a model that takes in X of shape $(m, T_x, 78)$ and Y of shape $(T_y, m, 78)$. We will use an LSTM with 64 dimensional hidden states. Lets set `n_a = 64`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's how you can create a Keras model with multiple inputs and outputs. \n",
    "\n",
    "The function `djmodel()` will call the LSTM layer $T_x$ times using a for-loop, and it is important that all $T_x$ copies have the same weights.ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸è¦æ¯æ¬¡éƒ½é‡æ–°åˆå§‹åŒ–æƒé‡ã€‚\n",
    "\n",
    "The key steps for implementing layers with shareable weights in Keras are: \n",
    "1. Define the layer objects (we will use global variables for this).\n",
    "2. Call these objects when propagating the input.\n",
    "\n",
    "We have defined the layers objects you need as global variables. Please run the next cell to create them. Please check the Keras documentation to make sure you understand what these layers are: [Reshape()](https://keras.io/layers/core/#reshape), [LSTM()](https://keras.io/layers/recurrent/#lstm), [Dense()](https://keras.io/layers/core/#dense).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapor = Reshape((1, 78))                        # Used in Step 2.B of djmodel(), below\n",
    "LSTM_cell = LSTM(n_a, return_state = True)         # Used in Step 2.C\n",
    "densor = Dense(n_values, activation='softmax')     # Used in Step 2.D\n",
    "\n",
    "#è¿™äº›éƒ½æ˜¯ç”¨æ¥æ„å»ºdjmodel()çš„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "**Exercise**: Implement `djmodel()`. You will need to carry out 2 steps:\n",
    "\n",
    "1. åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨outputsï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¿å­˜LSTMçš„è¾“å‡ºã€‚        .\n",
    "2. å¾ªç¯ $t \\in 1, \\ldots, T_x$:\n",
    "\n",
    "    A. ä»Xä¸­é€‰æ‹©ç¬¬tä¸ªæ—¶é—´æ­¥å‘é‡. Create a custom [Lambda](https://keras.io/layers/core/#lambda) layer in Keras by using this line of code:\n",
    "```    \n",
    "           x = Lambda(lambda x: X[:,t,:])(X)\n",
    "``` \n",
    "\n",
    "    B. Reshape x to be (1,78). You may find the `reshapor()` layer helpful.\n",
    "\n",
    "    C. Run x through one step of LSTM_cell. Remember to initialize the LSTM_cell with the previous step's hidden state $a$ and cell state $c$. Use the following formatting:\n",
    "```python\n",
    "a, _, c = LSTM_cell(input_x, initial_state=[previous hidden state, previous cell state])\n",
    "```\n",
    "\n",
    "    D. Propagate the LSTM's output activation value through a dense+softmax layer using `densor`. \n",
    "    \n",
    "    E. Append the predicted value to the list of \"outputs\"\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: djmodel\n",
    "\n",
    "def djmodel(Tx, n_a, n_values):\n",
    "    \"\"\"\n",
    "    Implement the model\n",
    "    \n",
    "    Arguments:\n",
    "    Tx -- length of the sequence in a corpusï¼Œ30\n",
    "    n_a -- the number of activations used in our modelï¼Œ64\n",
    "    n_values -- number of unique values in the music data ï¼Œ78\n",
    "    \n",
    "    Returns:\n",
    "    model -- a keras model with the \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    X = Input(shape=(Tx, n_values))\n",
    "    \n",
    "    # initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    # Step 1: Create empty list to append the outputs while you iterate (â‰ˆ1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop\n",
    "    for t in range(Tx):\n",
    "        \n",
    "        # Step 2.A: select the \"t\"th time step vector from X. \n",
    "        x = Lambda(lambda x:X[:, t, :])(X)\n",
    "        # Step 2.B: Use reshapor to reshape x to be (1, n_values) (â‰ˆ1 line)\n",
    "        x = reshapor(x)\n",
    "        # Step 2.C: Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "        # Step 2.E: add the output to \"outputs\"\n",
    "        outputs.append(out)\n",
    "        \n",
    "    # Step 3: Create model instance\n",
    "    model = Model(inputs=[X, a0, c0], outputs=outputs)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to define your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = djmodel(Tx = 30 , n_a = 64, n_values = 78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now need to compile your model to be trained. We will Adam and a categorical cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets initialize `a0` and `c0` for the LSTM's initial state to be zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = 60\n",
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now fit the model.\n",
    "\n",
    "We will turn `Y` to a list before doing so, since the cost function expects `Y` to be provided in this format (one list item per time-step). æ‰€ä»¥listï¼ˆYï¼‰æ˜¯ä¸€ä¸ªåŒ…å«30ä¸ªé¡¹çš„åˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªé¡¹éƒ½æ˜¯å½¢çŠ¶ï¼ˆ60,78ï¼‰ã€‚ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit([X, a0, c0], list(Y), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now that you have trained a model, lets go on the the final section to implement an inference algorithm, and generate some music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Generating music\n",
    "\n",
    "You now have a trained model. Lets now use this model to synthesize new music. \n",
    "\n",
    "#### 3.1 - Predicting & Sampling\n",
    "\n",
    "<img src=\"images/music_gen.png\" style=\"width:600;height:400px;\">\n",
    "\n",
    "\n",
    "\n",
    "<!-- \n",
    "You are about to build a function that will do this inference for you. Your function takes in your previous model and the number of time steps `Ty` that you want to sample. It will return a keras model that would be able to generate sequences for you. Furthermore, the function takes in a dense layer of `78` units and the number of activations. \n",
    "!--> \n",
    "\n",
    "\n",
    "**Exercise:** Implement the function below to sample a sequence of musical values. \n",
    "\n",
    "Step 2.A: Use `LSTM_Cell`, which inputs the previous step's `c` and `a` to generate the current step's `c` and `a`. \n",
    "\n",
    "Step 2.B: Use `densor` (defined previously) to compute a softmax on `a` to get the output for the current step. \n",
    "\n",
    "Step 2.C: Save the output you have just generated by appending it to `outputs`.\n",
    "\n",
    "Step 2.D: Sample x to the be \"out\"'s one-hot version (the prediction) so that you can pass it to the next LSTM's step.  We have already provided this line of code, which uses a [Lambda](https://keras.io/layers/core/#lambda) function. \n",
    "```python\n",
    "x = Lambda(one_hot)(out) \n",
    "```\n",
    "[ä¹Ÿå°±æ˜¯è¯´ï¼Œç”¨é¢„æµ‹å¾—åˆ°çš„æœ€å¯èƒ½çš„valueè½¬ä¸ºone-hot vectorï¼Œä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: music_inference_model\n",
    "\n",
    "def music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 100):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    n_values -- integer, number of unique values\n",
    "    n_a -- number of units in the LSTM_cell\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    \n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    x0 = Input(shape=(1, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values (â‰ˆ1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        \n",
    "        # Step 2.A: Perform one step of LSTM_cell (â‰ˆ1 line)\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        \n",
    "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (â‰ˆ1 line)\n",
    "        out = densor(a)\n",
    "\n",
    "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, 78) (â‰ˆ1 line)\n",
    "        outputs.append(out)\n",
    "        \n",
    "        # Step 2.D: Select the next value according to \"out\", and set \"x\" to be the one-hot representation of the\n",
    "        #           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided \n",
    "        #           the line of code you need to do this. \n",
    "        x = Lambda(one_hot)(out)\n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (â‰ˆ1 line)\n",
    "    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs)\n",
    "    \n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to define your inference model. This model is hard coded to generate 50 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this creates the zero-valued vectors you will use to initialize `x` and the LSTM state variables `a` and `c`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_initializer = np.zeros((1, 1, 78))\n",
    "a_initializer = np.zeros((1, n_a))\n",
    "c_initializer = np.zeros((1, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement `predict_and_sample()`. \n",
    "\n",
    "1. Use your inference model to predict an output given your set of inputs. The output `pred` should be a list of length 20 where each element is a numpy-array of shape ($T_y$, n_values)\n",
    "2. Convert `pred` into a numpy array of $T_y$ indices. Each index corresponds is computed by taking the `argmax` of an element of the `pred` list. [Hint](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html).\n",
    "3. Convert the indices into their one-hot vector representations. [Hint](https://keras.io/utils/#to_categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict_and_sample\n",
    "\n",
    "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
    "                       c_initializer = c_initializer):\n",
    "    \"\"\"\n",
    "    Predicts the next value of values using the inference model.\n",
    "    \n",
    "    Arguments:\n",
    "    inference_model -- Keras model instance for inference time\n",
    "    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation\n",
    "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
    "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
    "    \n",
    "    Returns:\n",
    "    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated\n",
    "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.\n",
    "    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])\n",
    "    # Step 2: Convert \"pred\" into an np.array() of indices with the maximum probabilities\n",
    "    indices = np.argmax(pred, axis=-1)\n",
    "    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )\n",
    "    results = to_categorical(indices, num_classes=78)\n",
    "\n",
    "    \n",
    "    return results, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)\n",
    "print(\"np.argmax(results[12]) =\", np.argmax(results[12]))\n",
    "print(\"np.argmax(results[17]) =\", np.argmax(results[17]))\n",
    "print(\"list(indices[12:18]) =\", list(indices[12:18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: Your results may differ because Keras' results are not completely predictable. However, if you have trained your LSTM_cell with model.fit() for exactly 100 epochs as described above, you should very likely observe a sequence of indices that are not all identical.\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "    \n",
    "**np.argmax(results[12])** =\n",
    "</td>\n",
    "<td>\n",
    "10\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "    \n",
    "**np.argmax(results[17])** =\n",
    "</td>\n",
    "<td>\n",
    "68\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "    \n",
    "**list(indices[12:18])** =\n",
    "</td>\n",
    "<td>\n",
    "[array([10]), array([54]), array([10]), array([3]), array([37]), array([68])]\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - Generate music \n",
    "\n",
    "Finally, you are ready to generate music. Your RNN generates a sequence of values. The following code generates music by first calling your `predict_and_sample()` function. These values are then post-processed into musical chords (meaning that multiple values or notes can be played at the same time). \n",
    "\n",
    "å¤§å¤šæ•°éŸ³ä¹ç®—æ³•ä¼šä½¿ç”¨ä¸€äº›åå¤„ç†ï¼Œå› ä¸ºå¦‚æœæ²¡æœ‰åå¤„ç†ï¼Œå¾ˆéš¾ç”Ÿæˆå¬èµ·æ¥ä¸é”™çš„éŸ³ä¹ã€‚æ¯”å¦‚ç¡®ä¿åŒä¸€ä¸ªå£°éŸ³ä¸é‡å¤å¤ªå¤šæ¬¡ï¼Œä¸¤ä¸ªè¿ç»­çš„éŸ³ç¬¦åœ¨éŸ³é«˜ä¸Šè·ç¦»ä¸å¤ªè¿œç­‰ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to generate music and record it into your `out_stream`. This can take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out_stream = generate_music(inference_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To listen to your music, click File->Open... Then go to \"output/\" and download \"my_music.midi\". Either play it on your computer with an application that can read midi files if you have one, or use one of the free online \"MIDI to mp3\" conversion tools to convert this to mp3.  \n",
    "\n",
    "As reference, here also is a 30sec audio clip we generated using this algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio('./data/30s_trained_model.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "The ideas presented in this notebook came primarily from three computational music papers cited below. The implementation here also took significant inspiration and used many components from Ji-Sung Kim's github repository.\n",
    "\n",
    "- Ji-Sung Kim, 2016, [deepjazz](https://github.com/jisungk/deepjazz)\n",
    "- Jon Gillick, Kevin Tang and Robert Keller, 2009. [Learning Jazz Grammars](http://ai.stanford.edu/~kdtang/papers/smc09-jazzgrammar.pdf)\n",
    "- Robert Keller and David Morrison, 2007, [A Grammatical Approach to Automatic Improvisation](http://smc07.uoa.gr/SMC07%20Proceedings/SMC07%20Paper%2055.pdf)\n",
    "- FranÃ§ois Pachet, 1999, [Surprising Harmonies](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.7473&rep=rep1&type=pdf)\n",
    "\n",
    "We're also grateful to FranÃ§ois Germain for valuable feedback."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "EG0F7",
   "launcher_item_id": "cxJXc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
